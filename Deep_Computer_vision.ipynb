{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Computer_vision.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNi5FiEmiQ64Y7jacZzmHXm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imakshit/Tensorflow/blob/master/Deep_Computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEPPIuisHndx",
        "colab_type": "text"
      },
      "source": [
        "#DEEP COMPUTER VISION\n",
        "\n",
        "\n",
        "WE will perform image classification and object detection/recognition using deep computer vision with **convolution neural networks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBBMUemHFdGP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "523d99fc-88ff-4554-8a21-a2e041e6ada2"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHxcOLJBHoz4",
        "colab_type": "text"
      },
      "source": [
        "#Dataset\n",
        "The problem we will consider here is classifying 10 different everyday objects. The dataset we will use is built into tensorflow and called the CIFAR Image Dataset. It contains 60,000 32x32 color images with 6000 images of each class.\n",
        "\n",
        "The labels in this dataset are the following:\n",
        "\n",
        "- Airplane\n",
        "- Automobile\n",
        "- Bird\n",
        "- Cat\n",
        "- Deer\n",
        "- Dog\n",
        "- Frog\n",
        "- Horse\n",
        "- Ship\n",
        "- Truck\n",
        "\n",
        "\n",
        "We'll load the dataset and have a look at some of the images below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_GeLi3pFfLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  LOAD AND SPLIT DATASET\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQSD0JUzFhE2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "ea3d6a46-e7c1-42a8-f2ce-de910de9313c"
      },
      "source": [
        "# Let's look at a one image\n",
        "IMG_INDEX = 7  # change this to look at other images\n",
        "\n",
        "plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
        "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEHCAYAAABoVTBwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vShcgxuYIlyS",
        "colab_type": "text"
      },
      "source": [
        "#CNN ARCHITECTURE\n",
        "\n",
        "A common architecture for a CNN is a stack of Conv2D and MaxPooling2D layers followed by a few denesly connected layers. The idea is that the stack of convolutional and maxPooling layers extract the features from the image. Then these features are flattened and fed to densly connected layers that determine the class of an image based on the presence of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0_hwGMuFjLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVY2VkyRI1RP",
        "colab_type": "text"
      },
      "source": [
        "**Layer 1**\n",
        "\n",
        "The input shape of our data will be 32, 32, 3 and we will process 32 filters of size 3x3 over our input data. We will also apply the activation function relu to the output of each convolution operation.\n",
        "\n",
        "**Layer 2**\n",
        "\n",
        "This layer will perform the max pooling operation using 2x2 samples and a stride of 2.\n",
        "\n",
        "**Other Layers**\n",
        "\n",
        "The next set of layers do very similar things but take as input the feature map from the previous layer. They also increase the frequency of filters from 32 to 64. We can do this as our data shrinks in spacial dimensions as it passed through the layers, meaning we can afford (computationally) to add more depth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4ur2KcRFwGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "263f306e-71f7-4bb5-bb22-58b0de55bdb9"
      },
      "source": [
        "model.summary()  # let's have a look at our model so far"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 56,320\n",
            "Trainable params: 56,320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9t9W43XI7VL",
        "colab_type": "text"
      },
      "source": [
        "**ADDING DENSE LAYERS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OczvQ-ToF0da",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGurHA0eF53P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "3ac6c4c5-ea0f-43d4-b083-7d4bc061da4b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 122,570\n",
            "Trainable params: 122,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OardhX5JAPj",
        "colab_type": "text"
      },
      "source": [
        "#TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxmVDE8FF7cp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "46d2d1f6-3b1d-4cb6-ae78-8d7457325da8"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=4, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/4\n",
            "50000/50000 [==============================] - 67s 1ms/sample - loss: 1.5527 - accuracy: 0.4333 - val_loss: 1.3247 - val_accuracy: 0.5205\n",
            "Epoch 2/4\n",
            "50000/50000 [==============================] - 66s 1ms/sample - loss: 1.2039 - accuracy: 0.5753 - val_loss: 1.1065 - val_accuracy: 0.6073\n",
            "Epoch 3/4\n",
            "50000/50000 [==============================] - 66s 1ms/sample - loss: 1.0609 - accuracy: 0.6265 - val_loss: 1.0132 - val_accuracy: 0.6416\n",
            "Epoch 4/4\n",
            "50000/50000 [==============================] - 66s 1ms/sample - loss: 0.9724 - accuracy: 0.6590 - val_loss: 0.9855 - val_accuracy: 0.6567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkxdEN6RJFc6",
        "colab_type": "text"
      },
      "source": [
        "#EVALUATING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQBxD_6BF-tu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c9f79cb2-7bb6-4c17-efe2-ef9867cbba4b"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 - 4s - loss: 0.9855 - accuracy: 0.6567\n",
            "0.6567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgSxFrASHN6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYit7MLEHOYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}